{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IKYN_qOcTPG"
   },
   "source": [
    "# Forecasting Project using the BIKE SHARING DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-7Fb2uhcTPI"
   },
   "source": [
    "## Introduction\n",
    "Welcome Techie!\n",
    "\n",
    "So far you've learned how to explore, clean, and visualize data as well as how to implement supervised and unsupervised machine learning models. Congratulations!\n",
    "\n",
    "In this notebook you are going to combine all these skills and knowledge to build a forecasting project for a bike sharing startup.\n",
    "\n",
    "Start by watching the video below to recall which machine learning steps are important. \n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "Kb8axoJxcTPJ",
    "outputId": "bafdf988-2439-4e59-db50-5539d783fceb"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"400\"\n",
       "            src=\"https://www.youtube.com/embed/nKW8Ndu7Mjw\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x10601ef60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('nKW8Ndu7Mjw', width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very helpful and good video which summarises steps of a machine learning project in a short and nice way.\n",
    "\n",
    "But do you agree with everything in the video? Can we generalize every machine learning project into these steps? I don't want to critizes the video. I just want you to think critically.\n",
    "\n",
    "It is hard to say \"Do exactly these 7 things during a machine learning project and everything will work\". All problems and also machine learning problems are contextual. Thus, what all problems have in common are not the single steps and solutions but the questions that always come up.\n",
    "\n",
    "As an example. Instead of saying \"I have to randomize the data and split it into training and testing\", ask \"What is the best way to split my data?\". We will see later why this is important.\n",
    "\n",
    "The video also mostly described a classification problem but what if you have a regression problem? Can you use the same steps? We will uncover this question in this notebook since we have a regression problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your experience\n",
    "Briefly sketch out what you think should be included into a data science project. \n",
    "Which steps are necessary? What have you learnt so far during the online courses?  \n",
    "You can write your ideas here into the cell below or grab pen and paper (as I often do) and write down each step which you would add to a data science project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUrnQfPPcTPQ"
   },
   "source": [
    "## Learning Goals\n",
    "\n",
    "It is time for you to implement your <b><font color='blue'>frist machine learning (ML) models</font></b> from skretch and practice what you have learnt so far. Additionally, the goal of this notebook is to introduce you to a <b><font color='blue'>Data Science Hypothesis Process</font></b> which you can use later for your own projects. This process will allow you to make data science projects repeatable by establishing a machine learning strategy instead of a machine learning snapshot.\n",
    "\n",
    "The notebook is structured in such a way that you will go through a whole data science project. From a short data <b><font color='blue'>exploration</font></b> to data <b><font color='blue'>cleaning</font></b> and <b><font color='blue'>preparation</font></b> to <b><font color='blue'>formulating hypotheses** and **building ML models</font></b> which you then evaluate and refine.\n",
    "\n",
    "After finishing this notebook you should feel more confident starting data science projects. You will know which questions/steps are important and relevant during a data science project and how to train and evaluate ML models. With this practice it will be easier for you to work with your team and solve your next data science problem.\n",
    "\n",
    "Everything you will need to do will be inside of this notebook, and I've marked which cells you will need to edit by saying <b><font color='red'>\"TODO! COMPLETE THIS SECTION!\"</font></b>. Inside the cells you'll find `...`. These are the places where you have to add your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCSSHIMWcTPS"
   },
   "source": [
    "## Practice with Bike Sharing dataset\n",
    "\n",
    "Before you start make sure you read the README pdf file inside the unzipped folder.\n",
    "\n",
    "Let's build a story and client problem around the dataset so that it feels more realistic and gives us a sense of solving a real world problem.\n",
    "\n",
    "A Münster-based startup called LeezenShare is a bike sharing startup with five stores distributed around the city. Their bike sharing service is on the rise but recently they faced a wave of complaints from customers and employees. \n",
    "\n",
    "Most of the customers have two issues. Frist, they are reporting the stores at Hafenstraße and Königsweg don't have enough available bikes on the spot. Second, at store Weseler Str., where a lot of bikes are available they have to wait a very long time before an employee can help them. Employees on the other hand feel overwhelmed with the work at store Weseler Straße and are very stressed because of the huge number of customers in the stores.\n",
    "\n",
    "So the startup LeezenShare approached you - the data scientist - for help. They want to improve their customer and employee experience at their stores by making better decisions on how to distribute bikes across the stores. They want a forecasting system from you so that they know when and where bikes are needed. For the start they give you only the data of one store. You have to prove to them that you can build a forecasting system and help them at that one store.\n",
    "\n",
    "Challenge accepted.\n",
    "\n",
    "### import libraries\n",
    "First import some libraries we need for some data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QOAscN3cTPT"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySw-IK3tcTPW"
   },
   "source": [
    "### first impression and information about the dataset\n",
    "\n",
    "First, load and explore the data before diving into the machine learning models. You have to get a feeling what kind of data your are dealing with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tK0g33UcTPX"
   },
   "source": [
    "Import bike sharing dataset by loading the `bikesharing.csv` file.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-i9uzplcTPX"
   },
   "outputs": [],
   "source": [
    "# Import the csv file using pandas\n",
    "df = pd..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tK0g33UcTPX"
   },
   "source": [
    "Check how many rows and columns the dataset has and display the first 5 rows.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the shape of the data set\n",
    "df..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the first five rows of the data set\n",
    "df..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you see which columns and information are available to you. Below you can find a more detailed description of the columns.\n",
    "\n",
    "**Column discribtion**\n",
    "\n",
    "- datetime: date + hourly time\n",
    "- season: 1 = spring, 2 = summer, 3 = fall, 4 = winter\n",
    "- holiday: whether the day is considered a holiday \n",
    "  - 0: no holiday \n",
    "  - 1: holiday\n",
    "- workingday\n",
    "  - 0: no workingday\n",
    "  - 1: workingday\n",
    "- weather -\n",
    "  - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "  - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "  - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "  - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "- temp: temperature in Celsius\n",
    "- atemp: \"feels like\" temperature in Celsius\n",
    "- humidity: relative humidity\n",
    "- windspeed: wind speed\n",
    "- casual: number of non-registered user rentals initiated\n",
    "- registered: number of registered user rentals initiated\n",
    "- count: number of total rentals (Dependent Variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to change a small thing before you do further explorations. The \"count\" column is the target column. But \"count\" as column name is a bad choice since a pandas method is also called .count(). Thus let's rename the count column to \"target\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'count': 'target'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tK0g33UcTPX"
   },
   "source": [
    "Now that we have changed the column name, let's continue with the data exploration. Check the column types. Does the datetime column really contain datetime type of data?\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the column types of the data set\n",
    "df..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are mostly of type integer or float. But the datetime column is of type object even though it is supposed to be of type datetime. Thus change the datetime column to datetime type.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a pandas method to change the type of the datetime column to datetime\n",
    "df.datetime = pd..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look again, if the datetime column has the right type now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, now the datetime column has the type datetime64[ns].\n",
    "\n",
    "Since we have a unique timeseries, set the datetime column as index. \n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the datetime column as index. Don't forget to use the inplace variable\n",
    "df...\n",
    "\n",
    "# this will just test if you set the index correct\n",
    "message = (\n",
    "    \"You have to set the index inplace. The \"\n",
    "    \"datetime columnn should only exist as \"\n",
    "    \"an index and not as a column anymore.\")\n",
    "assert df.shape[1] == 11, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how the data set looks with datetime as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tK0g33UcTPX"
   },
   "source": [
    "Now find out what the date range of the data set is.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the minimum datetime\n",
    "df..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the maximum datetime\n",
    "df..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tK0g33UcTPX"
   },
   "source": [
    "As you found out, we have approximately two years of data.\n",
    "\n",
    "But do we have information on every single day and every single hour? This is very important for the machine learning models which you are going to implement. If no or only a few values are missing you can utilize the time series information perfectly by using models built explicitly for time series. But if you find out that the data contains a lot of missing values, you should select different machine learning models. Thus check if the data contains missing values in the form of nan values. \n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many null/nan values do the columns have\n",
    "df..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tK0g33UcTPX"
   },
   "source": [
    "Nice. There are no null/nan values. But before we celebrate, let's check if the data set contains every datetime in the date range you found.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of datetimes starting from the minimum date of the dataset\n",
    "# to the maximum date of the data set. \n",
    "idx = pd...\n",
    "assert len(idx) == 17256, \"Did you set the frequency to hours?\"\n",
    "\n",
    "# reindex the data set and fill missing values with nan\n",
    "df = df.reindex(idx, fill_value=pd.np.nan)\n",
    "\n",
    "# get a list of datetimes where the target is nan\n",
    "missing = df...\n",
    "message = (\n",
    "    \"Something went wrong. Check if you \"\n",
    "    \"reindexed the data set correctly or if you \"\n",
    "    \"selected the the nan target values correctly.\")\n",
    "assert len(missing) == 6370, message\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok we don't have the information for every single day and every single hour. How many percent of the data is missing?\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(...) / len(...) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tK0g33UcTPX"
   },
   "source": [
    "Approximately 37%. That's a lot of missing data. Let's find out how many days are affected and how much data is missing on each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "missing_dates = [x.date() for x in missing]\n",
    "count = Counter(missing_dates)\n",
    "missing_dates = pd.DataFrame(list(count.items()), columns=['date', 'missing_count'])\n",
    "print('The dataset has missing values at ' + str(len(missing_dates)) + ' different days.')\n",
    "missing_dates.hist(figsize=(18, 6), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is missing on 305 days and most of the days are missing completely as you can see in the histogram plot (the largest bin is at 24)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tK0g33UcTPX"
   },
   "source": [
    "Plot the time series target data to see more clearly when data is missing. Is it only missing at the start of the time series or at the end? Or is the data missing periodically?\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the target column\n",
    "df['target']..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is missing frequently and in large intervalls. This is a big problem. Typically one can use time series models, like SARIMA or Prophet, for revenue forecasting to utilize the time dependency. But with these large gaps of missing data it is hard to use these models in a meaningful way.\n",
    "\n",
    "But it is great to find this out so early. This eliminates certain types of models which means we have to rely on other models. And we have to consider this while engineering the features for our models (features like target of one week before will be difficult to engineer since we have a lot of missing data).\n",
    "\n",
    "For machine leanring models it is better to use normally distributed data. Skewed data could cause problems for the machine learning model and therefore bad forecasting performance.\n",
    "\n",
    "Check if the data is skewed by plotting a histogramm for the target.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a histogram plot of the target column\n",
    "df['target']..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the data looks skewed. This means we have to clean the data and fix the skewness.\n",
    "\n",
    "All these steps you are doing are important for building a machine learning model. Thus I hope that you aren't frustrated that we haven't already started building the model. But the model part isn't that complicated and all this ground work you did until now will be included into the machine learning project you are going to build.\n",
    "\n",
    "The next step will be our last task. After fixing and scaling the skewed data, you will start with the Data Science Hypothesis Process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning data\n",
    "\n",
    "There are many different ways how you can fix skewed data. You can google \"python fixing skewed data\" and you will find different articles with methods and explanations. Here we will use the log-transform to make our data less skewed. \n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the log method from numpy to transfrom the target\n",
    "df['norm_target'] = np...\n",
    "df.norm_target.hist(figsize=(18, 6), bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. The data looks more like a normal distribution now. It is still skewed but ok, this is the best we can do for now. If you want, feel free to google other transformations and try to fix the skewed data even more.\n",
    "\n",
    "Besides transforming the data, another important step is to scale the data. Do you remember why it is important from your online courses?\n",
    "\n",
    "In the next step you will use the StandardScaler method from sklearn to scale the target. You will only scale the target value for now to see how it effects the values. Later during the machine learning models you will have to scale also other numerical feature columns so that the numerical values are all in the same range and your ML model doesn't favor certain features.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# reload the data, because the StandardScaler cannot \n",
    "# handle nan values\n",
    "df = pd.read_csv('bikesharing.csv')\n",
    "df.rename(columns={'count': 'target'}, inplace=True)\n",
    "\n",
    "# create a StandardScaler object\n",
    "sc = ...\n",
    "df['norm_target'] = np.log(df['target'])\n",
    "# fit transform the norm_target column\n",
    "df['norm_target'] = sc...\n",
    "df.norm_target.hist(figsize=(18, 6), bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the histogram plot the distribution didn't change at all. The scaling only shifted the distribution to values mostly around -1 and 1.\n",
    "\n",
    "Now it is time for the Data Science Hypothesis Process and for implementing machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Hypothesis Process - baseline model\n",
    "Now we are going to start our data science hypothesis process. The idea of this process is to have a repeatable project process which you can use over and over again. The first step in this process is to **formulate a hypothesis**. After that, it is time to **implement and test your hypothesis**. For this you have to engineer new features, implement a new model or whatever your hypothesis requires. After implementing everthing you have to **evaluate the hypothesis** and validate it or disprove it. Depending on the outcome you **refine your hypothesis or define a new one** and the process starts again. The idea of this process is to make fast iterations of your machine learning project, test new ideas and improve the model step by step.\n",
    "\n",
    "To make use of this process, you need to have a baseline model to which you can compare later hypotheses and results. So let's build the baseline model.\n",
    "\n",
    "All the steps you did until now are very important for your baseline model and later ML project steps. To make your machine leanring project repeatable and flexible you will first implement some of the steps above and new ones into functions so that you can use the functions over and over again. The different steps will include:\n",
    "\n",
    "- loading data\n",
    "- engineering features\n",
    "- fixing skewed data\n",
    "- generate dummy variables\n",
    "- split feature and target\n",
    "- split the data into training and testing sets\n",
    "- scale target\n",
    "- make the prediction and save it\n",
    "- evaluate predictions\n",
    "\n",
    "It is very important that you implement these steps into functions because we will use them in all hypothesis steps.\n",
    "\n",
    "In the following you are also going to build your first baseline model in the **make predictions phase** with first simple features which you engineer in the  **engineering feature step**.\n",
    "\n",
    "This was a lot of text, but I hope I could give you an idea on how the hypothesis process works and why it is important to build the first functions. Enough reading. Let's start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first function will load the data and make first preparations. Implement the function in the following cell and run the function in the second cell below to see if it works. (Feel free to just scroll to the top and copy paste the things you already implemented). The asserts in the second cell are only to check if everything is implemented correctly.\n",
    "\n",
    "From now on the frist cell is used to implement functions and in the second cell you will use these functions to build your machine learning project step by step.\n",
    "\n",
    "Feel free to also create your own cells to test ideas before you implement them into the functions. Experiment a bit. But don't forget to delete those experiment cells again.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    # load the bikesharing csv\n",
    "    ts = pd...\n",
    "\n",
    "    # rename count column to target\n",
    "    ts...\n",
    "\n",
    "    # change the type of the datetime column to datetime\n",
    "    ts['datetime'] = pd...\n",
    "\n",
    "    # set the datetime column as index\n",
    "    ts...\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "df = load_and_prepare_data()\n",
    "\n",
    "assert 'target' in df.columns, \"The target is missing.\"\n",
    "assert 'count' not in df.columns, \"Count is still in dataframe.\"\n",
    "assert type(df.index) == pd.DatetimeIndex, \"The datetime is not the index or not of type datetime\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. You implemented the first function. Now it's time to engineer some features for your ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### engineer  datatime features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineer the first features from the datetime information. You will focus only on the datetime features for now to build your first base model. Later you will formulate hypotheses to check if the other features can improve your model. \n",
    "\n",
    "In the second cell we will use the load_and_prepare_data funciton you implemented above and add the new functions to see if everything runs smoothly.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hours(ts):\n",
    "    # get the hour information from the datetime index\n",
    "    ts['hour'] = ts...\n",
    "    return ts\n",
    "\n",
    "def add_isodate(ts):\n",
    "    # get the year, week and weekday information from the datetime index\n",
    "    ts[['year', 'week', 'weekday']] = pd.DataFrame(\n",
    "        ts.index.map(lambda x: x.isocalendar()).tolist(), index=ts.index)\n",
    "    return ts\n",
    "\n",
    "def add_month(ts):\n",
    "    # get the month information from the datetime index\n",
    "    ts['month'] = ts...\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "df = load_and_prepare_data()\n",
    "\n",
    "# drop unnecessary columns\n",
    "cols = ['season', 'holiday', 'workingday', \n",
    "        'weather', 'temp', 'atemp', 'humidity', \n",
    "        'windspeed', 'casual', 'registered']\n",
    "df.drop(columns=cols, inplace=True)\n",
    "\n",
    "# feature engineering\n",
    "df = add_hours(df)\n",
    "df = add_isodate(df)\n",
    "df = add_month(df)\n",
    "\n",
    "assert 'target' in df.columns, \"The target columns is missing.\"\n",
    "for col in ['hour', 'year', 'week', 'month', 'weekday']:\n",
    "    assert col in df.columns, \"The %s feature is missing.\" % col\n",
    "assert len(df.columns) == 6, \"You have to many columns in your dataframe.\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now that you have engineered some features, let's move on to fixing the skewed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fix skewed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier in the notebook we saw that the data is a bit skewed and you used the log-tansform to fix the skewed data. Now it is time to build this transformation into a function and add it as a next step into your project after loading the data and engineering features.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_skewed_data(ts):\n",
    "    # use the numpy log transfrom method to transform the target data\n",
    "    ts['target'] = np...\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "df = load_and_prepare_data()\n",
    "\n",
    "# drop columns\n",
    "cols = ['season', 'holiday', 'workingday', \n",
    "        'weather', 'temp', 'atemp', 'humidity', \n",
    "        'windspeed', 'casual', 'registered']\n",
    "df.drop(columns=cols, inplace=True)\n",
    "\n",
    "# feature engineering\n",
    "df = add_hours(df)\n",
    "df = add_isodate(df)\n",
    "df = add_month(df)\n",
    "\n",
    "# transfrom to fix skewed data\n",
    "df = fix_skewed_data(df)\n",
    "\n",
    "assert len(df.columns) == 6, \"You have to many columns. Did you create a new target column?\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a nice process where you first load the data, engineer some features and then fix the skewed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have categorical features, it is a good idea to create dummy variables for them. (If you don't remember what dummy variables are feel free to google it.)\n",
    "\n",
    "Now one can argue if datetime features like for example months are really categorical features, since they contain time dependent information. On the other hand, why should the model value December (12) more than January (1). It also depends on what model you are using. Are you using a regression model or a tree-based model.\n",
    "\n",
    "The only way to find out if the normal features or the dummified features are the better choice is to test it. Therefore build a function that creates dummy variables out of feature columns.\n",
    "\n",
    "Again, feel free to also create your own cells to test ideas before you implement them into the functions. Experiment a bit. But don't forget to delete those cells again.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummies(ts, cols, trap=False):\n",
    "    # iterate over each column which you want to dummify\n",
    "    for col ...:\n",
    "        # create dummy variables out of the column\n",
    "        dummies = pd...\n",
    "        # if trap is true we will drop one of the \n",
    "        # created dummies to avoid the dummy trap problem\n",
    "        if trap:\n",
    "            ts = ts.join(dummies.iloc[:, :-1])\n",
    "        else:\n",
    "            ts = ts.join(dummies)\n",
    "    # drop the normal columns since you now have dummy variables\n",
    "    ts...\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "df = load_and_prepare_data()\n",
    "\n",
    "# drop columns\n",
    "cols = ['season', 'holiday', 'workingday', \n",
    "        'weather', 'temp', 'atemp', 'humidity', \n",
    "        'windspeed', 'casual', 'registered']\n",
    "df.drop(columns=cols, inplace=True)\n",
    "\n",
    "# feature engineering\n",
    "df = add_hours(df)\n",
    "df = add_isodate(df)\n",
    "df = add_month(df)\n",
    "\n",
    "# transfrom to fix skewed data\n",
    "df = fix_skewed_data(df)\n",
    "\n",
    "# generate dummies\n",
    "cols = ['hour', 'year', 'week', 'weekday', 'month']\n",
    "df = generate_dummies(df, cols)\n",
    "\n",
    "# assers will try to test if you implemented everything correctly\n",
    "for col in cols:\n",
    "    message = (\n",
    "        \"You have to drop the %s column because you created \"\n",
    "        \"dummies now.\" % col)\n",
    "    assert col not in df.columns, message\n",
    "assert len(df.columns) == 93, \"Either you have too many columns or you have too few.\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully created dummy features we are closer to our machine learning model. The next steps are to split the data set into features and targets and after that to split the data again into training and testing sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataframe into target and features dataframes so that you can train your machine learning model later.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "df = load_and_prepare_data()\n",
    "\n",
    "# drop columns\n",
    "cols = ['season', 'holiday', 'workingday', \n",
    "        'weather', 'temp', 'atemp', 'humidity', \n",
    "        'windspeed', 'casual', 'registered']\n",
    "df.drop(columns=cols, inplace=True)\n",
    "\n",
    "# feature engineering\n",
    "df = add_hours(df)\n",
    "df = add_isodate(df)\n",
    "df = add_month(df)\n",
    "\n",
    "# transfrom to fix skewed data\n",
    "df['target'] = np.log(df.target)\n",
    "\n",
    "# generate dummies\n",
    "cols = ['hour', 'year', 'week', 'weekday', 'month']\n",
    "df = generate_dummies(df, cols)\n",
    "\n",
    "# split target and feature\n",
    "# store the features in X and the target in y\n",
    "# (select feature columns by excluding the target column\n",
    "# instead of typing every feature column name manually)\n",
    "X = df.loc[...\n",
    "y = df.loc[...\n",
    "\n",
    "# asserts are only here to test\n",
    "assert type(X) == pd.DataFrame, \"X should be a DataFrame.\"\n",
    "assert type(y) == pd.DataFrame, \"y should be a DataFrame.\"\n",
    "assert 'target' not in X.columns, \"The target columns shouldn't be in the feature dataframe X.\"\n",
    "assert len(y.columns) == 1, \"The target dataframe y should only include the target column.\"\n",
    "\n",
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the dataframe into target and features, the next step is to split your datasets into training and testing.\n",
    "\n",
    "In the video at the beginning of this notebook, the instructor told you to randomize the data before splitting it into training and tests. This is correct for a lot of problems like classification problems or some regression problems but not for forecasting problems. Randomizing your data would break the time dependent structure and it could be that you have future information in your training set which your model shouldn't see.\n",
    "\n",
    "Therefore you will pick a starting date (2012-08-01) and an end date (7 days). The starting and end date are the intervalls for the testing dataset. The data before the start date will be the training dataset.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "df = load_and_prepare_data()\n",
    "\n",
    "# drop columns\n",
    "cols = ['season', 'holiday', 'workingday', \n",
    "        'weather', 'temp', 'atemp', 'humidity', \n",
    "        'windspeed', 'casual', 'registered']\n",
    "df.drop(columns=cols, inplace=True)\n",
    "\n",
    "# feature engineering\n",
    "df = add_hours(df)\n",
    "df = add_isodate(df)\n",
    "df = add_month(df)\n",
    "\n",
    "# transfrom to fix skewed data\n",
    "df['target'] = np.log(df.target)\n",
    "\n",
    "# generate dummies\n",
    "cols = ['hour', 'year', 'week', 'weekday', 'month']\n",
    "df = generate_dummies(df, cols)\n",
    "\n",
    "# split target and feature\n",
    "X = df.loc[:, df.columns != 'target']\n",
    "y = df.loc[:, ['target']]\n",
    "\n",
    "# save predictions in dataframe\n",
    "preds = pd.DataFrame()\n",
    "\n",
    "# pick the date interval for train and test\n",
    "# the start date should be of type timestamp\n",
    "# and should be the 2012-08-01 for now\n",
    "start = pd...\n",
    "# add 7 days to the start date using pandas Timedelta\n",
    "end = start + pd...\n",
    "\n",
    "# test a few things\n",
    "assert type(start) == pd.Timestamp, \"start is not of type timestamp\"\n",
    "assert type(end) == pd.Timestamp, \"end is not of type timestamp\"\n",
    "\n",
    "# select train and test data\n",
    "# select the train and test features\n",
    "X_train = X[X.index < start]\n",
    "X_test = X[(X.index >= start) & (X.index <= end)]\n",
    "\n",
    "# select the train and test targets\n",
    "y_train = y[...\n",
    "y_test = y[..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now display your dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train.head())\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y_train.head())\n",
    "display(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are so close to implementing the machine learning model. The last step left which seperates you from your machine learning model is to scale the target data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scale the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good idea to scale all the numerical columns in your dataset so that your model doesn't favor some columns over others because they have larger values.\n",
    "\n",
    "The only numerical column we have until now is the target column since we are dropping other columns like temperature for now and have only dummy features for our datetime features.\n",
    "\n",
    "Scale the target values using the StandardScaler method from sklearn. \n",
    "\n",
    "While scaling, it is important that you first fit your scaler on the training data. After you fitted the scaler on the training data use the same scaler to transform your test data. This is important because during real life forecasting you wouldn't know what your test target values are because the test target values are supposed to be future values. \n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_targets(y_train, y_test):\n",
    "    sc = StandardScaler()\n",
    "    # fit and transfrom the target values of your train data\n",
    "    y_train['target_sc'] = sc... \n",
    "    \n",
    "    # transfrom the targeet values of your test data\n",
    "    # and save it as target_sc\n",
    "    y_test['target_sc'] = sc... \n",
    "    \n",
    "    # output the scaler and both training and testing datasets\n",
    "    # you will need the scaler later to retransfrom your predictions \n",
    "    # back to real target values\n",
    "    return sc, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "df = load_and_prepare_data()\n",
    "\n",
    "# drop columns\n",
    "cols = ['season', 'holiday', 'workingday', \n",
    "        'weather', 'temp', 'atemp', 'humidity', \n",
    "        'windspeed', 'casual', 'registered']\n",
    "df.drop(columns=cols, inplace=True)\n",
    "\n",
    "# feature engineering\n",
    "df = add_hours(df)\n",
    "df = add_isodate(df)\n",
    "df = add_month(df)\n",
    "\n",
    "# transfrom to fix skewed data\n",
    "df['target'] = np.log(df.target)\n",
    "\n",
    "# generate dummies\n",
    "cols = ['hour', 'year', 'week', 'weekday', 'month']\n",
    "df = generate_dummies(df, cols)\n",
    "\n",
    "# split target and feature\n",
    "X = df.loc[:, df.columns != 'target']\n",
    "y = df.loc[:, ['target']]\n",
    "\n",
    "# save predictions in dataframe\n",
    "preds = pd.DataFrame()\n",
    "\n",
    "# start forward test. pick date interval for train and test\n",
    "start = pd.Timestamp('2012-08-01')\n",
    "end = start + pd.Timedelta(7, unit='D')\n",
    "\n",
    "# select train and test data\n",
    "X_train = X[X.index < start]\n",
    "X_test = X[(X.index >= start) & (X.index <= end)]\n",
    "\n",
    "y_train = y[y.index < start]\n",
    "y_test = y[(y.index >= start) & (y.index <= end)]\n",
    "\n",
    "sc, y_train, y_test = scale_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y_train.head())\n",
    "display(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work. Now it's time to implement the machine learning model, train it and make first predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make predictions and save them\n",
    "You will use a simple DecisionTree Regressor as your first base model. If you are not familiar with DecisionTrees it's totally fine. During the online courses you learned how to implement a Linear Regressor. The DecisionTree follows the same implementation principles. That's the beauty of sklearn. \n",
    "\n",
    "If you need more information, google \"sklearn decision tree regressor\" or check out this link from sklearn https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html where you can find the information on how to implement the model.\n",
    "\n",
    "If you want to learn more about how DecisionTrees work, check out this YouTube video https://www.youtube.com/watch?v=eKD5gxPPeY0 (The example in the video is a classification problem but it should give a small introduction on how decision trees work.)\n",
    "\n",
    "Now:\n",
    "1. implement the decision tree\n",
    "2. fit you model on the training dataset\n",
    "3. predict with your model using the test dataset\n",
    "4. store the predictions in your y test dataset as prediction_sc (your model outputs scaled values because we trained it on scaled values)\n",
    "5. rescale the predictions\n",
    "6. retransfrom the predicitons (don't forget you implemented the log transfrom method to fix the skewed data. To get back to real values you have to retransform the log values.)\n",
    "\n",
    "Everything below is what you have implemented so far. This is the whole project you built step by step.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# load and prepare data\n",
    "df = load_and_prepare_data()\n",
    "\n",
    "# drop columns\n",
    "cols = ['season', 'holiday', 'workingday', \n",
    "        'weather', 'temp', 'atemp', 'humidity', \n",
    "        'windspeed', 'casual', 'registered']\n",
    "df.drop(columns=cols, inplace=True)\n",
    "\n",
    "# feature engineering\n",
    "df = add_hours(df)\n",
    "df = add_isodate(df)\n",
    "df = add_month(df)\n",
    "\n",
    "# transfrom to fix skewed data\n",
    "df['target'] = np.log(df.target)\n",
    "\n",
    "# generate dummies\n",
    "cols = ['hour', 'year', 'week', 'weekday', 'month']\n",
    "df = generate_dummies(df, cols)\n",
    "\n",
    "# split target and feature\n",
    "X = df.loc[:, df.columns != 'target']\n",
    "y = df.loc[:, ['target']]\n",
    "\n",
    "# save predictions in dataframe\n",
    "preds = pd.DataFrame()\n",
    "\n",
    "# start forward test. pick date interval for train and test\n",
    "start = pd.Timestamp('2012-08-01')\n",
    "end = start + pd.Timedelta(7, unit='D')\n",
    "\n",
    "# select train and test data\n",
    "X_train = X[X.index < start]\n",
    "X_test = X[(X.index >= start) & (X.index <= end)]\n",
    "\n",
    "y_train = y[y.index < start]\n",
    "y_test = y[(y.index >= start) & (y.index <= end)]\n",
    "\n",
    "sc, y_train, y_test = scale_targets(y_train, y_test)\n",
    "\n",
    "# create a decision tree regressor model\n",
    "reg = ...\n",
    "# fit the model using the training dataset\n",
    "# don't forget to train the model on the scaled target (target_sc)\n",
    "reg...\n",
    "\n",
    "# make predictions using the test features\n",
    "pred = reg...\n",
    "\n",
    "# add pred to y_test\n",
    "y_test['prediction_sc'] = pred\n",
    "\n",
    "# rescale/inverse-transfrom the predictions using the StandardScaler sc\n",
    "y_test['prediction'] = sc...\n",
    "\n",
    "# retransform the target and the prediction values so that \n",
    "# we have our real values back (we used the log transformation earlier)\n",
    "y_test['target'] = np.exp(y_test.target)\n",
    "y_test['prediction'] = np.exp(y_test.prediction)\n",
    "\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations you did your first predictions. Great work. \n",
    "\n",
    "Now it is time to evaluate the predictions. How good is your model?\n",
    "\n",
    "From now on you will copy-paste your whole code from above and add or change a few things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define an error metric to evaluate the performance of our forecasting model. There are a lot of different error metrics we can use but a simple and straight forward metric is the MAPE metric which is implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(y, y_hat):\n",
    "    perc_err = (100 * (y - y_hat)) / y\n",
    "    return pd.np.mean(abs(perc_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy your project code from above and paste it here above the calculate_mape function and run the cell.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "mape = calculate_mape(y_test.target, y_test.prediction)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAPE should be approx. `20.83` (The number could be slightly different for you). \n",
    "\n",
    "Now define a plot function which you can use to visualize the target and predictions, and the error (difference between target and predictions).\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(ts):\n",
    "    # create two plot.\n",
    "    # the first plot should show the target (blue) and the prediction (green)\n",
    "    # the second plot should show the error (predicton - target)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy your project code from above (including the MAPE calculation) and past it here above the plot_error function and run the cell.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "plot_error(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look something like this ![](https://drive.google.com/uc?export=view&id=1joUiYlKehuV9G18FLXZw8aDiPC0O65i1):\n",
    "\n",
    "Good work! You built a nice code structure to make predictions and to evaluate them. The target follows a certain pattern with two repeating peaks from day to day and your model was able to predict them accurately most of the time. Your model even predicted the two days which don't follow the two-peak-pattern.\n",
    "\n",
    "The next step would be to test multiple prediction windows, not only from 2012-08-01 until 2012-08-08. This method is called forward-testing (or back-testing) and it is the equivalent to a cross validation method you would normally use. Forward-testing is typically used to evaluate forecasting systems.\n",
    "\n",
    "The forward-testing method isn't available like cross validation in sklearn. Thus we would have to implement it ourselves. But the implementation is out of scope of this notebook. If you are still interested in how the forward-testing can be implemented, let me know or feel free to google it and built it yourself. \n",
    "\n",
    "Now that you have a nice code structure it is time for our first hypothesis and to improve your forecasting project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Hypothesis Cycle 1 - Random Forest\n",
    "\n",
    "After training and defining our baseline with the decision tree model and the datetime feature, it is time to improve the model. We will do this by defining a hypothesis and proving or disproving the hypothesis. We want to improve the forecasting performance iteration by iteration, which also means if you disprove a hypothesis and your forecasting system didn't improve, it is totally fine.\n",
    "\n",
    "In this first round we will try to improve the forecasting performance with a more complicated model (only the model itself is a bit more sophisticated. The implementation follows the same pattern with .fit and .predict so it is as easy as before). \n",
    "\n",
    "As base model you used the DecisionTree, now we want to improve the model performance by using multiple DecisionTrees. The model with multiple DecisionTrees is called RandomForest. \n",
    "\n",
    "____\n",
    "#### Hypothesis\n",
    "The forecasting performance will improve with a model upgrade from DecisionTree to RandomForest.\n",
    "___\n",
    "\n",
    "Copy your latest code structure with the evaluation step in it and replace the decision tree with a ramdom forest model.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You improved the model performance from `20.07` to `19.24` (The number could be slightly different for you) and thus proved your first hypothesis. (Keep in mind the ideal way of testing a hypothesis would be by using the forward testing method).\n",
    "\n",
    "Let's formulate the  next hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Hypothesis Cycle 2 - Season feature \n",
    "\n",
    "Now let's add an additional feature, the season feature, to your model and see if the forecasting performance can be further improved.\n",
    "\n",
    "Before randomly adding the feature, let's make a quick visualization to see if the season feature could be a relevant feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_prepare_data()\n",
    "df = df[['season', 'target']]\n",
    "df['hour'] = df.index.hour\n",
    "df['day'] = df.index.day\n",
    "\n",
    "hourly = df[['hour', 'season', 'target']].groupby(\n",
    "    ['hour', 'season']).mean().reset_index()\n",
    "daily = df[['day', 'season', 'target']].groupby(\n",
    "    ['day', 'season']).mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.pointplot(\n",
    "    x=hourly['hour'], y=hourly['target'], \n",
    "    hue=hourly['season'], data=hourly)\n",
    "plt.title(\"Grouped target for of each season vs hour\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.pointplot(\n",
    "    x=daily['day'], y=daily['target'], \n",
    "    hue=daily['season'], data=daily)\n",
    "plt.title(\"Grouped target for of each season vs day in month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This quick visualization shows us that the spring season (1) has a lower count of rented bikes. Thus the season feature could improve our model by separating the spring season better from the other seasons.\n",
    "\n",
    "___\n",
    "#### Hypothesis\n",
    "The season feature will improve the model performance because the spring season has a lower count of rented bikes.\n",
    "___\n",
    "\n",
    "Let's try it out. Implement a season feature into your forecasting system.\n",
    "\n",
    "Copy the code from where you implemented the RandomForestRegression model.\n",
    "\n",
    "Remove the season column from the drop columns list so that the season feature is available for your model. Also don't forget to generate dummy variables for the season feature. Add the season feature to the column list for which you generate dummy variables.\n",
    "\n",
    "Finally run the code again and check if you could improve the model performance even further.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The season feature improved the model from `19.23` to `16.94` for this one week (The number could be slightly different for you). Hypothesis proved. \n",
    "\n",
    "Let's try out another feature in our next hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Hypothesis Cycle 3 - Temperature feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's include a numerical feature into our model. Logically it makes sense that more bikes are rented if the weather is nicer. Therefore let's see if a temperature feature can improve the model.\n",
    "\n",
    "But again, before just throwing the feature at the model, we will check if the temperature correlates with our target value (count of rented bikes).\n",
    "\n",
    "Calculate the correlation between the temperature and the target.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_prepare_data()\n",
    "# calculate the correlation (if you don't know how google \"pandas correlation\")\n",
    "corr = df[['temp', 'target']]...\n",
    "sns.heatmap(corr, cmap='Blues', annot=corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation plot shows a positive correlation between the target and temperature. Thus the temperature feature could improve our model.\n",
    "\n",
    "___\n",
    "#### Hypothesis\n",
    "People are renting more bikes at higher temperatures. Thus a temperature feature will improve our model.\n",
    "___\n",
    "\n",
    "Keep in mind that you have to scale the temperature data after you split the data into train and test sets.\n",
    "\n",
    "First, build a new function that scales the training data by fitting and transforming it and scale the test data afterwards by using the scaler which was fitted on the traing data set.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_feature(train, test, col):\n",
    "    sc = ...\n",
    "    # fit and transfrom train[[col]]\n",
    "    train[col] = sc...\n",
    "    \n",
    "    # transfrom the test data\n",
    "    test[col] = sc... \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again copy and paste your last forecasting code from where you implemented the season feature.\n",
    "\n",
    "Add your new function (`scale_feautre`) after the target scaler function (`scale_targets`). Don't forget to remove the temp column from the list of dropped columns and input the temp column name into your `scale_feature` function.\n",
    "\n",
    "<h4><font color='red'>TODO! COMPLETE THIS SECTION!</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. the performance for this one week improved again from `16.94` to `15.22`. (The number could be slightly different for you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Hypothesis Cycle 4 - Your ideas\n",
    "\n",
    "Now it's time for you to be creative. You can now try your own ideas. There are a lot of features we haven't tried yet like the holiday feature or the humidity feature. \n",
    "\n",
    "But you can also come up with self designed features. Earlier we used the season feature because we saw that the spring season has lower bike rental counts. We included the default season feature with all four seasons but you could engineer a more specific feature which contains the information if it is spring season or not (new column named \"spring\". 0 - not spring; 1 - spring). Maybe the model can make use of this more specific feature. \n",
    "\n",
    "If you want, you can also implement the forward-testing method to test if the ML model and all the features you added improve other weeks and time intervals too or if we just picked a lucky time intervall where all features improve the model.\n",
    "\n",
    "Keep in mind to either generate dummy variables if you are dealing with categorical features or to scale the data after splitting it into training and testings sets if you have numerical features.\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4t4S6yxcTPR"
   },
   "source": [
    "## Summary and Outlook\n",
    "You built a complete project from scratch. Not only did you explore and clean the data but you also engineered features and implemented a machine learning model which is trained, tested and evaluated.\n",
    "\n",
    "This notebook was supposed to be a short introduction on how you can combine all the things you have learnt so far to start your own data science (machine learning) projects.\n",
    "\n",
    "Keep in mind that the steps for other problems like classification problems or regression problems which are not forecasts can vary. But now you should know what questions to ask, like: What is the best way to scale the data? How should I split my data? What is the best approach to evaluate my model?\n",
    "\n",
    "If you found the hypothesis process useful, use it in your own projects. If something is missing or too much, please iterate on the idea and change it, so that it suits your work style.\n",
    "\n",
    "The next steps from here on can include:\n",
    "- buidling the forward-testing method to truely test how your model is performing.\n",
    "- creating external .py files where you store all your functions, which you implement in the notebook here. External .py files will make it easier for you to share your code, make your code more production ready and work more efficient in teams.\n",
    "\n",
    "Let me know if you have interest in bringing this notebook and code structure to production by implementing all the functions inside .py files and creating a useful project-folder-system or if you want to know how to implement the forward-testing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
